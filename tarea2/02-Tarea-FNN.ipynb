{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"02-Tarea-FNN.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"IHikpAuqJPa0"},"source":["Integrantes:\n","\n","1. Ignacio Morande\n","2. Fernando Contreras\n","3. Alberto Bella"]},{"cell_type":"markdown","metadata":{"id":"Qoe8C6GiM-py"},"source":["# Tarea 2\n","\n","# Parte práctica (3 puntos)\n","La NASA mantiene la información de varios cometas y quiere determinar alguna manera de predecir el diametro de un cometa. Específicamente, han analizado en forma manual una muestra de 100.000 asteroides. Los datos consisten en 27 variables, con distinta información como por ejemplo nombre del asteroide, su periodo orbital, su periodo de rotación, etc. Todos los datos existentes, se encuentran en un puro archivo llamado asteroidTrain.csv. Mientras que las descripciones de cada una de las variables se encuentran en el archivo tarea2Informacion.txt\n","\n","Desafortunadamente, la NASA todavía no ha evaluado 37.681 asteroides y no tienen tiempo para realizarlo. Por lo mismo, le piden que aplique una red neuronal feed forward para obtener una predicción de estos asteroides.\n","\n","1. Lea los datos y borre las variables/asteroides que estime necesario. En caso que crea que la base de datos todavía es demasiado grande para aplicar los modelos, usted puede tomar una muestra de la misma (1.5 punto).\n","2. Entrene un modelo feed forward. Realice una busqueda de parámetros modifique el número de capas, de neuronas, funciones de activación, epocas, etc. Seleccione un solo modelo de los seleccionados y muestre ese modelo (0.5 puntos).\n","3. Seleccione uno de los modelos del punto anterior y evalue los 37.681 asteroides que la NASA no ha evaluado. Se deberá generar un archivo csv con 37.681 filas, cada fila deberá ser una estimación (1 punto). \n","\n","El punto de evaluación final será una competencia entre todas las tareas basados en los MSE más bajo obtenido por cada grupo. El puntaje final será una regresión lineal entre el peor y mejor puntaje."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":464},"id":"nQrULnS0M-p5","executionInfo":{"status":"ok","timestamp":1618280840213,"user_tz":240,"elapsed":1366,"user":{"displayName":"Alberto Bella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfYhx5QL_c7uquJXJuQgNtrIRd8B-UtT93xJ-G=s64","userId":"01742836384906309226"}},"outputId":"bfa6aabc-b76a-4bbc-9d0f-9b942fbac991"},"source":["import numpy as np\n","import tensorflow as tf\n","import pandas as pd\n","from plotnine import *\n","import matplotlib.pyplot as plt\n","\n","df_test = pd.read_csv('asteroidEval.csv')\n","df = pd.read_csv('asteroidTrain.csv')\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (14) have mixed types.Specify dtype option on import or set low_memory=False.\n","  interactivity=interactivity, compiler=compiler, result=result)\n","/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (14,15) have mixed types.Specify dtype option on import or set low_memory=False.\n","  interactivity=interactivity, compiler=compiler, result=result)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>full_name</th>\n","      <th>a</th>\n","      <th>e</th>\n","      <th>G</th>\n","      <th>i</th>\n","      <th>om</th>\n","      <th>w</th>\n","      <th>q</th>\n","      <th>ad</th>\n","      <th>per_y</th>\n","      <th>data_arc</th>\n","      <th>condition_code</th>\n","      <th>n_obs_used</th>\n","      <th>H</th>\n","      <th>diameter</th>\n","      <th>extent</th>\n","      <th>albedo</th>\n","      <th>rot_per</th>\n","      <th>GM</th>\n","      <th>BV</th>\n","      <th>UB</th>\n","      <th>IR</th>\n","      <th>spec_B</th>\n","      <th>spec_T</th>\n","      <th>neo</th>\n","      <th>pha</th>\n","      <th>moid</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>97632 (2000 EL145)</td>\n","      <td>3.069866</td>\n","      <td>0.184417</td>\n","      <td>NaN</td>\n","      <td>3.620920</td>\n","      <td>308.458533</td>\n","      <td>249.570070</td>\n","      <td>2.503729</td>\n","      <td>3.636003</td>\n","      <td>5.378824</td>\n","      <td>6803.0</td>\n","      <td>0.0</td>\n","      <td>614</td>\n","      <td>14.6</td>\n","      <td>6.611</td>\n","      <td>NaN</td>\n","      <td>0.070</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>1.50522</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>49808 (1999 XD40)</td>\n","      <td>2.386539</td>\n","      <td>0.104566</td>\n","      <td>NaN</td>\n","      <td>13.003513</td>\n","      <td>105.866881</td>\n","      <td>329.104052</td>\n","      <td>2.136988</td>\n","      <td>2.636089</td>\n","      <td>3.686897</td>\n","      <td>7672.0</td>\n","      <td>0.0</td>\n","      <td>1247</td>\n","      <td>14.7</td>\n","      <td>4.255</td>\n","      <td>NaN</td>\n","      <td>0.170</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>1.16197</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>390390 (2013 WC84)</td>\n","      <td>3.018175</td>\n","      <td>0.084529</td>\n","      <td>NaN</td>\n","      <td>14.247933</td>\n","      <td>245.449168</td>\n","      <td>115.242451</td>\n","      <td>2.763053</td>\n","      <td>3.273297</td>\n","      <td>5.243544</td>\n","      <td>5904.0</td>\n","      <td>0.0</td>\n","      <td>181</td>\n","      <td>15.6</td>\n","      <td>5.625</td>\n","      <td>NaN</td>\n","      <td>0.024</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>1.79743</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>14319 (1978 US5)</td>\n","      <td>2.793049</td>\n","      <td>0.290215</td>\n","      <td>NaN</td>\n","      <td>16.677722</td>\n","      <td>17.862425</td>\n","      <td>287.769691</td>\n","      <td>1.982465</td>\n","      <td>3.603633</td>\n","      <td>4.667948</td>\n","      <td>25107.0</td>\n","      <td>0.0</td>\n","      <td>955</td>\n","      <td>14.0</td>\n","      <td>4.224</td>\n","      <td>NaN</td>\n","      <td>0.324</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>1.04034</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>321079 (2008 SW97)</td>\n","      <td>2.721394</td>\n","      <td>0.098602</td>\n","      <td>NaN</td>\n","      <td>1.975506</td>\n","      <td>271.706257</td>\n","      <td>248.448520</td>\n","      <td>2.453059</td>\n","      <td>2.989728</td>\n","      <td>4.489472</td>\n","      <td>8027.0</td>\n","      <td>0.0</td>\n","      <td>251</td>\n","      <td>16.4</td>\n","      <td>3.525</td>\n","      <td>NaN</td>\n","      <td>0.043</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>1.46299</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             full_name         a         e   G  ...  spec_T  neo  pha     moid\n","0   97632 (2000 EL145)  3.069866  0.184417 NaN  ...     NaN    N    N  1.50522\n","1    49808 (1999 XD40)  2.386539  0.104566 NaN  ...     NaN    N    N  1.16197\n","2   390390 (2013 WC84)  3.018175  0.084529 NaN  ...     NaN    N    N  1.79743\n","3     14319 (1978 US5)  2.793049  0.290215 NaN  ...     NaN    N    N  1.04034\n","4   321079 (2008 SW97)  2.721394  0.098602 NaN  ...     NaN    N    N  1.46299\n","\n","[5 rows x 27 columns]"]},"metadata":{"tags":[]},"execution_count":125}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":407},"id":"JIai1kArRpBQ","executionInfo":{"status":"ok","timestamp":1618280841627,"user_tz":240,"elapsed":709,"user":{"displayName":"Alberto Bella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfYhx5QL_c7uquJXJuQgNtrIRd8B-UtT93xJ-G=s64","userId":"01742836384906309226"}},"outputId":"a85b1813-0042-4326-9861-3b0fb015ef9d"},"source":["# G, extent, rot_per, GM, BVm UB, IR, spec_B, spec_T: to many NaN\n","# full_name: not relevant info\n","# neo, pha: binary variable\n","# condition_code: categorical variable\n","drop_col = ['full_name', 'G', 'extent', 'rot_per', 'GM', 'BV', 'UB', 'IR', 'spec_B', 'spec_T', 'condition_code', 'neo', 'pha']\n","\n","df_train = df.drop(columns = drop_col)\n","df_test = df_test.drop(columns = drop_col)\n","df_train = df_train.dropna() # Elimina filas con NaN\n","df_test = df_test.dropna()\n","df_train # Quedan 98837 filas"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>a</th>\n","      <th>e</th>\n","      <th>i</th>\n","      <th>om</th>\n","      <th>w</th>\n","      <th>q</th>\n","      <th>ad</th>\n","      <th>per_y</th>\n","      <th>data_arc</th>\n","      <th>n_obs_used</th>\n","      <th>H</th>\n","      <th>diameter</th>\n","      <th>albedo</th>\n","      <th>moid</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3.069866</td>\n","      <td>0.184417</td>\n","      <td>3.620920</td>\n","      <td>308.458533</td>\n","      <td>249.570070</td>\n","      <td>2.503729</td>\n","      <td>3.636003</td>\n","      <td>5.378824</td>\n","      <td>6803.0</td>\n","      <td>614</td>\n","      <td>14.6</td>\n","      <td>6.611</td>\n","      <td>0.070</td>\n","      <td>1.50522</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2.386539</td>\n","      <td>0.104566</td>\n","      <td>13.003513</td>\n","      <td>105.866881</td>\n","      <td>329.104052</td>\n","      <td>2.136988</td>\n","      <td>2.636089</td>\n","      <td>3.686897</td>\n","      <td>7672.0</td>\n","      <td>1247</td>\n","      <td>14.7</td>\n","      <td>4.255</td>\n","      <td>0.170</td>\n","      <td>1.16197</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3.018175</td>\n","      <td>0.084529</td>\n","      <td>14.247933</td>\n","      <td>245.449168</td>\n","      <td>115.242451</td>\n","      <td>2.763053</td>\n","      <td>3.273297</td>\n","      <td>5.243544</td>\n","      <td>5904.0</td>\n","      <td>181</td>\n","      <td>15.6</td>\n","      <td>5.625</td>\n","      <td>0.024</td>\n","      <td>1.79743</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2.793049</td>\n","      <td>0.290215</td>\n","      <td>16.677722</td>\n","      <td>17.862425</td>\n","      <td>287.769691</td>\n","      <td>1.982465</td>\n","      <td>3.603633</td>\n","      <td>4.667948</td>\n","      <td>25107.0</td>\n","      <td>955</td>\n","      <td>14.0</td>\n","      <td>4.224</td>\n","      <td>0.324</td>\n","      <td>1.04034</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2.721394</td>\n","      <td>0.098602</td>\n","      <td>1.975506</td>\n","      <td>271.706257</td>\n","      <td>248.448520</td>\n","      <td>2.453059</td>\n","      <td>2.989728</td>\n","      <td>4.489472</td>\n","      <td>8027.0</td>\n","      <td>251</td>\n","      <td>16.4</td>\n","      <td>3.525</td>\n","      <td>0.043</td>\n","      <td>1.46299</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>99994</th>\n","      <td>2.758028</td>\n","      <td>0.092627</td>\n","      <td>1.994054</td>\n","      <td>173.649449</td>\n","      <td>216.612757</td>\n","      <td>2.502559</td>\n","      <td>3.013496</td>\n","      <td>4.580428</td>\n","      <td>8978.0</td>\n","      <td>878</td>\n","      <td>14.9</td>\n","      <td>3.356</td>\n","      <td>0.157</td>\n","      <td>1.50731</td>\n","    </tr>\n","    <tr>\n","      <th>99996</th>\n","      <td>2.715932</td>\n","      <td>0.239266</td>\n","      <td>16.789523</td>\n","      <td>34.531718</td>\n","      <td>44.097353</td>\n","      <td>2.066102</td>\n","      <td>3.365761</td>\n","      <td>4.475963</td>\n","      <td>6595.0</td>\n","      <td>201</td>\n","      <td>16.1</td>\n","      <td>4.724</td>\n","      <td>0.055</td>\n","      <td>1.11044</td>\n","    </tr>\n","    <tr>\n","      <th>99997</th>\n","      <td>3.188786</td>\n","      <td>0.278970</td>\n","      <td>15.177104</td>\n","      <td>188.342499</td>\n","      <td>255.934423</td>\n","      <td>2.299209</td>\n","      <td>4.078363</td>\n","      <td>5.694376</td>\n","      <td>5377.0</td>\n","      <td>141</td>\n","      <td>15.8</td>\n","      <td>4.148</td>\n","      <td>0.059</td>\n","      <td>1.36906</td>\n","    </tr>\n","    <tr>\n","      <th>99998</th>\n","      <td>2.754535</td>\n","      <td>0.106028</td>\n","      <td>8.758664</td>\n","      <td>230.483443</td>\n","      <td>34.567890</td>\n","      <td>2.462477</td>\n","      <td>3.046593</td>\n","      <td>4.571730</td>\n","      <td>7973.0</td>\n","      <td>835</td>\n","      <td>15.0</td>\n","      <td>2.749</td>\n","      <td>0.177</td>\n","      <td>1.45246</td>\n","    </tr>\n","    <tr>\n","      <th>99999</th>\n","      <td>3.940892</td>\n","      <td>0.241022</td>\n","      <td>9.495628</td>\n","      <td>192.657992</td>\n","      <td>197.808221</td>\n","      <td>2.991051</td>\n","      <td>4.890732</td>\n","      <td>7.823479</td>\n","      <td>17141.0</td>\n","      <td>2036</td>\n","      <td>10.8</td>\n","      <td>35.679</td>\n","      <td>0.067</td>\n","      <td>1.99740</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>98837 rows × 14 columns</p>\n","</div>"],"text/plain":["              a         e          i  ...  diameter  albedo     moid\n","0      3.069866  0.184417   3.620920  ...     6.611   0.070  1.50522\n","1      2.386539  0.104566  13.003513  ...     4.255   0.170  1.16197\n","2      3.018175  0.084529  14.247933  ...     5.625   0.024  1.79743\n","3      2.793049  0.290215  16.677722  ...     4.224   0.324  1.04034\n","4      2.721394  0.098602   1.975506  ...     3.525   0.043  1.46299\n","...         ...       ...        ...  ...       ...     ...      ...\n","99994  2.758028  0.092627   1.994054  ...     3.356   0.157  1.50731\n","99996  2.715932  0.239266  16.789523  ...     4.724   0.055  1.11044\n","99997  3.188786  0.278970  15.177104  ...     4.148   0.059  1.36906\n","99998  2.754535  0.106028   8.758664  ...     2.749   0.177  1.45246\n","99999  3.940892  0.241022   9.495628  ...    35.679   0.067  1.99740\n","\n","[98837 rows x 14 columns]"]},"metadata":{"tags":[]},"execution_count":126}]},{"cell_type":"code","metadata":{"id":"AH6XkDFis1kP","colab":{"base_uri":"https://localhost:8080/","height":438},"executionInfo":{"status":"ok","timestamp":1618281558217,"user_tz":240,"elapsed":794,"user":{"displayName":"Alberto Bella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfYhx5QL_c7uquJXJuQgNtrIRd8B-UtT93xJ-G=s64","userId":"01742836384906309226"}},"outputId":"18221ca9-dc33-4bca-e688-2d1034cf9e19"},"source":["from sklearn.model_selection import train_test_split\n","\n","# outliers\n","\n","# sampling\n","X = df_train[['H', 'albedo', 'i', 'w', 'om', 'a', 'q']].astype(np.float32) # 'H', 'albedo', 'i', 'w', 'om', 'a'\n","y = df_train[['diameter']].astype(np.float32)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)\n","\n","# gridsearch\n","df_train.corr(method='pearson')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>a</th>\n","      <th>e</th>\n","      <th>i</th>\n","      <th>om</th>\n","      <th>w</th>\n","      <th>q</th>\n","      <th>ad</th>\n","      <th>per_y</th>\n","      <th>data_arc</th>\n","      <th>n_obs_used</th>\n","      <th>H</th>\n","      <th>albedo</th>\n","      <th>moid</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>a</th>\n","      <td>1.000000</td>\n","      <td>0.020140</td>\n","      <td>0.145463</td>\n","      <td>0.000677</td>\n","      <td>-0.003938</td>\n","      <td>0.351115</td>\n","      <td>0.986323</td>\n","      <td>0.937665</td>\n","      <td>-0.020186</td>\n","      <td>-0.050478</td>\n","      <td>-0.132787</td>\n","      <td>-0.112676</td>\n","      <td>0.354295</td>\n","    </tr>\n","    <tr>\n","      <th>e</th>\n","      <td>0.020140</td>\n","      <td>1.000000</td>\n","      <td>0.144074</td>\n","      <td>0.000618</td>\n","      <td>0.011340</td>\n","      <td>-0.530544</td>\n","      <td>0.114501</td>\n","      <td>0.046154</td>\n","      <td>-0.025897</td>\n","      <td>-0.075504</td>\n","      <td>0.195677</td>\n","      <td>-0.017901</td>\n","      <td>-0.507438</td>\n","    </tr>\n","    <tr>\n","      <th>i</th>\n","      <td>0.145463</td>\n","      <td>0.144074</td>\n","      <td>1.000000</td>\n","      <td>-0.010225</td>\n","      <td>-0.005617</td>\n","      <td>0.090659</td>\n","      <td>0.136505</td>\n","      <td>0.089660</td>\n","      <td>-0.189003</td>\n","      <td>-0.219579</td>\n","      <td>-0.038256</td>\n","      <td>-0.087733</td>\n","      <td>0.130376</td>\n","    </tr>\n","    <tr>\n","      <th>om</th>\n","      <td>0.000677</td>\n","      <td>0.000618</td>\n","      <td>-0.010225</td>\n","      <td>1.000000</td>\n","      <td>-0.108038</td>\n","      <td>-0.003120</td>\n","      <td>0.001258</td>\n","      <td>0.001395</td>\n","      <td>0.002191</td>\n","      <td>-0.024764</td>\n","      <td>0.003344</td>\n","      <td>0.000486</td>\n","      <td>-0.003735</td>\n","    </tr>\n","    <tr>\n","      <th>w</th>\n","      <td>-0.003938</td>\n","      <td>0.011340</td>\n","      <td>-0.005617</td>\n","      <td>-0.108038</td>\n","      <td>1.000000</td>\n","      <td>-0.009009</td>\n","      <td>-0.002542</td>\n","      <td>-0.001936</td>\n","      <td>-0.003755</td>\n","      <td>0.011688</td>\n","      <td>-0.009793</td>\n","      <td>-0.000882</td>\n","      <td>-0.009146</td>\n","    </tr>\n","    <tr>\n","      <th>q</th>\n","      <td>0.351115</td>\n","      <td>-0.530544</td>\n","      <td>0.090659</td>\n","      <td>-0.003120</td>\n","      <td>-0.009009</td>\n","      <td>1.000000</td>\n","      <td>0.191985</td>\n","      <td>0.090924</td>\n","      <td>-0.019968</td>\n","      <td>-0.084227</td>\n","      <td>-0.382581</td>\n","      <td>-0.271085</td>\n","      <td>0.996854</td>\n","    </tr>\n","    <tr>\n","      <th>ad</th>\n","      <td>0.986323</td>\n","      <td>0.114501</td>\n","      <td>0.136505</td>\n","      <td>0.001258</td>\n","      <td>-0.002542</td>\n","      <td>0.191985</td>\n","      <td>1.000000</td>\n","      <td>0.966789</td>\n","      <td>-0.017642</td>\n","      <td>-0.038081</td>\n","      <td>-0.071832</td>\n","      <td>-0.070380</td>\n","      <td>0.195871</td>\n","    </tr>\n","    <tr>\n","      <th>per_y</th>\n","      <td>0.937665</td>\n","      <td>0.046154</td>\n","      <td>0.089660</td>\n","      <td>0.001395</td>\n","      <td>-0.001936</td>\n","      <td>0.090924</td>\n","      <td>0.966789</td>\n","      <td>1.000000</td>\n","      <td>-0.007804</td>\n","      <td>-0.010632</td>\n","      <td>-0.033245</td>\n","      <td>-0.019190</td>\n","      <td>0.092174</td>\n","    </tr>\n","    <tr>\n","      <th>data_arc</th>\n","      <td>-0.020186</td>\n","      <td>-0.025897</td>\n","      <td>-0.189003</td>\n","      <td>0.002191</td>\n","      <td>-0.003755</td>\n","      <td>-0.019968</td>\n","      <td>-0.017642</td>\n","      <td>-0.007804</td>\n","      <td>1.000000</td>\n","      <td>0.750927</td>\n","      <td>-0.672794</td>\n","      <td>0.253907</td>\n","      <td>-0.027549</td>\n","    </tr>\n","    <tr>\n","      <th>n_obs_used</th>\n","      <td>-0.050478</td>\n","      <td>-0.075504</td>\n","      <td>-0.219579</td>\n","      <td>-0.024764</td>\n","      <td>0.011688</td>\n","      <td>-0.084227</td>\n","      <td>-0.038081</td>\n","      <td>-0.010632</td>\n","      <td>0.750927</td>\n","      <td>1.000000</td>\n","      <td>-0.783566</td>\n","      <td>0.448320</td>\n","      <td>-0.093925</td>\n","    </tr>\n","    <tr>\n","      <th>H</th>\n","      <td>-0.132787</td>\n","      <td>0.195677</td>\n","      <td>-0.038256</td>\n","      <td>0.003344</td>\n","      <td>-0.009793</td>\n","      <td>-0.382581</td>\n","      <td>-0.071832</td>\n","      <td>-0.033245</td>\n","      <td>-0.672794</td>\n","      <td>-0.783566</td>\n","      <td>1.000000</td>\n","      <td>-0.241802</td>\n","      <td>-0.378578</td>\n","    </tr>\n","    <tr>\n","      <th>albedo</th>\n","      <td>-0.112676</td>\n","      <td>-0.017901</td>\n","      <td>-0.087733</td>\n","      <td>0.000486</td>\n","      <td>-0.000882</td>\n","      <td>-0.271085</td>\n","      <td>-0.070380</td>\n","      <td>-0.019190</td>\n","      <td>0.253907</td>\n","      <td>0.448320</td>\n","      <td>-0.241802</td>\n","      <td>1.000000</td>\n","      <td>-0.275786</td>\n","    </tr>\n","    <tr>\n","      <th>moid</th>\n","      <td>0.354295</td>\n","      <td>-0.507438</td>\n","      <td>0.130376</td>\n","      <td>-0.003735</td>\n","      <td>-0.009146</td>\n","      <td>0.996854</td>\n","      <td>0.195871</td>\n","      <td>0.092174</td>\n","      <td>-0.027549</td>\n","      <td>-0.093925</td>\n","      <td>-0.378578</td>\n","      <td>-0.275786</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   a         e         i  ...         H    albedo      moid\n","a           1.000000  0.020140  0.145463  ... -0.132787 -0.112676  0.354295\n","e           0.020140  1.000000  0.144074  ...  0.195677 -0.017901 -0.507438\n","i           0.145463  0.144074  1.000000  ... -0.038256 -0.087733  0.130376\n","om          0.000677  0.000618 -0.010225  ...  0.003344  0.000486 -0.003735\n","w          -0.003938  0.011340 -0.005617  ... -0.009793 -0.000882 -0.009146\n","q           0.351115 -0.530544  0.090659  ... -0.382581 -0.271085  0.996854\n","ad          0.986323  0.114501  0.136505  ... -0.071832 -0.070380  0.195871\n","per_y       0.937665  0.046154  0.089660  ... -0.033245 -0.019190  0.092174\n","data_arc   -0.020186 -0.025897 -0.189003  ... -0.672794  0.253907 -0.027549\n","n_obs_used -0.050478 -0.075504 -0.219579  ... -0.783566  0.448320 -0.093925\n","H          -0.132787  0.195677 -0.038256  ...  1.000000 -0.241802 -0.378578\n","albedo     -0.112676 -0.017901 -0.087733  ... -0.241802  1.000000 -0.275786\n","moid        0.354295 -0.507438  0.130376  ... -0.378578 -0.275786  1.000000\n","\n","[13 rows x 13 columns]"]},"metadata":{"tags":[]},"execution_count":135}]},{"cell_type":"code","metadata":{"id":"nEzPrHvMgyH0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618282116363,"user_tz":240,"elapsed":555899,"user":{"displayName":"Alberto Bella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfYhx5QL_c7uquJXJuQgNtrIRd8B-UtT93xJ-G=s64","userId":"01742836384906309226"}},"outputId":"c0a97193-6acd-411c-a87b-4ba7e4e718b3"},"source":["from tensorflow.keras import *\n","\n","#Creating and training a model\n","inputLayer = layers.Input(shape=(7,))\n","hiddenLayer = layers.Dense(9, activation='linear',use_bias = True)(inputLayer)\n","hiddenLayer2 = layers.Dense(7, activation='linear',use_bias = True)(hiddenLayer)\n","hiddenLayer3 = layers.Dense(5, activation='linear',use_bias = True)(hiddenLayer2)\n","outputLayer = layers.Dense(1, activation='linear',use_bias = True)(hiddenLayer3)\n","\n","feedForward = models.Model(inputLayer, outputLayer)\n","feedForward.compile(loss='MeanSquaredError', optimizer = 'adam', metrics=['RootMeanSquaredError'])\n","feedForward.fit(X_train[:10000], y_train[:10000], epochs=400, batch_size=8, shuffle=True, verbose=0)\n","\n","# variar bach-size y epochs\n","\n","# variar capas y neuronas\n","resultado = feedForward.evaluate(X_test, y_test, return_dict=True)\n","resultado"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1082/1082 [==============================] - 2s 1ms/step - loss: 41.3677 - root_mean_squared_error: 6.4318\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'loss': 41.367713928222656, 'root_mean_squared_error': 6.431773662567139}"]},"metadata":{"tags":[]},"execution_count":136}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RgPJw2baFPui","executionInfo":{"status":"ok","timestamp":1618282218202,"user_tz":240,"elapsed":816,"user":{"displayName":"Alberto Bella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfYhx5QL_c7uquJXJuQgNtrIRd8B-UtT93xJ-G=s64","userId":"01742836384906309226"}},"outputId":"3e070787-60dd-45ad-83c7-e3505bd82242"},"source":["resultado"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'loss': 41.367713928222656, 'root_mean_squared_error': 6.431773662567139}"]},"metadata":{"tags":[]},"execution_count":137}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":407},"id":"5_9_W5ZdDkDa","executionInfo":{"status":"ok","timestamp":1618282222042,"user_tz":240,"elapsed":721,"user":{"displayName":"Alberto Bella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfYhx5QL_c7uquJXJuQgNtrIRd8B-UtT93xJ-G=s64","userId":"01742836384906309226"}},"outputId":"caa97abe-5629-44fd-bbd4-915341d3becf"},"source":["df_test"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>a</th>\n","      <th>e</th>\n","      <th>i</th>\n","      <th>om</th>\n","      <th>w</th>\n","      <th>q</th>\n","      <th>ad</th>\n","      <th>per_y</th>\n","      <th>data_arc</th>\n","      <th>n_obs_used</th>\n","      <th>H</th>\n","      <th>albedo</th>\n","      <th>moid</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3.969733</td>\n","      <td>0.082587</td>\n","      <td>6.263280</td>\n","      <td>159.529531</td>\n","      <td>338.904665</td>\n","      <td>3.641886</td>\n","      <td>4.297579</td>\n","      <td>7.909520</td>\n","      <td>14333.0</td>\n","      <td>2241</td>\n","      <td>11.0</td>\n","      <td>0.058</td>\n","      <td>2.656530</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2.262880</td>\n","      <td>0.096618</td>\n","      <td>22.340191</td>\n","      <td>52.502912</td>\n","      <td>87.172523</td>\n","      <td>2.044245</td>\n","      <td>2.481515</td>\n","      <td>3.404085</td>\n","      <td>2.0</td>\n","      <td>13</td>\n","      <td>17.1</td>\n","      <td>0.076</td>\n","      <td>1.174060</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3.072270</td>\n","      <td>0.103533</td>\n","      <td>9.503231</td>\n","      <td>217.293949</td>\n","      <td>191.020252</td>\n","      <td>2.754189</td>\n","      <td>3.390352</td>\n","      <td>5.385145</td>\n","      <td>10318.0</td>\n","      <td>1588</td>\n","      <td>13.0</td>\n","      <td>0.111</td>\n","      <td>1.763990</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2.766916</td>\n","      <td>0.208954</td>\n","      <td>10.208236</td>\n","      <td>161.123803</td>\n","      <td>188.856431</td>\n","      <td>2.188758</td>\n","      <td>3.345075</td>\n","      <td>4.602590</td>\n","      <td>10363.0</td>\n","      <td>664</td>\n","      <td>15.0</td>\n","      <td>0.044</td>\n","      <td>1.182110</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2.361788</td>\n","      <td>0.259924</td>\n","      <td>9.486384</td>\n","      <td>100.768260</td>\n","      <td>231.685109</td>\n","      <td>1.747903</td>\n","      <td>2.975672</td>\n","      <td>3.629690</td>\n","      <td>15207.0</td>\n","      <td>803</td>\n","      <td>15.7</td>\n","      <td>0.161</td>\n","      <td>0.753967</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>37676</th>\n","      <td>3.948805</td>\n","      <td>0.121336</td>\n","      <td>12.100826</td>\n","      <td>176.921861</td>\n","      <td>253.018391</td>\n","      <td>3.469671</td>\n","      <td>4.427939</td>\n","      <td>7.847055</td>\n","      <td>8811.0</td>\n","      <td>263</td>\n","      <td>14.5</td>\n","      <td>0.044</td>\n","      <td>2.510560</td>\n","    </tr>\n","    <tr>\n","      <th>37677</th>\n","      <td>2.985065</td>\n","      <td>0.085091</td>\n","      <td>9.437864</td>\n","      <td>165.845432</td>\n","      <td>49.880238</td>\n","      <td>2.731062</td>\n","      <td>3.239067</td>\n","      <td>5.157495</td>\n","      <td>9062.0</td>\n","      <td>706</td>\n","      <td>14.4</td>\n","      <td>0.111</td>\n","      <td>1.737330</td>\n","    </tr>\n","    <tr>\n","      <th>37678</th>\n","      <td>2.250727</td>\n","      <td>0.146572</td>\n","      <td>4.952574</td>\n","      <td>136.066108</td>\n","      <td>218.906512</td>\n","      <td>1.920834</td>\n","      <td>2.580621</td>\n","      <td>3.376701</td>\n","      <td>7823.0</td>\n","      <td>483</td>\n","      <td>16.1</td>\n","      <td>0.242</td>\n","      <td>0.917571</td>\n","    </tr>\n","    <tr>\n","      <th>37679</th>\n","      <td>2.692312</td>\n","      <td>0.182102</td>\n","      <td>14.004905</td>\n","      <td>177.379901</td>\n","      <td>92.464686</td>\n","      <td>2.202038</td>\n","      <td>3.182587</td>\n","      <td>4.417702</td>\n","      <td>6147.0</td>\n","      <td>434</td>\n","      <td>15.9</td>\n","      <td>0.088</td>\n","      <td>1.240040</td>\n","    </tr>\n","    <tr>\n","      <th>37680</th>\n","      <td>2.976344</td>\n","      <td>0.086984</td>\n","      <td>12.570232</td>\n","      <td>90.159809</td>\n","      <td>275.399609</td>\n","      <td>2.717450</td>\n","      <td>3.235237</td>\n","      <td>5.134910</td>\n","      <td>6384.0</td>\n","      <td>140</td>\n","      <td>15.9</td>\n","      <td>0.025</td>\n","      <td>1.752340</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>37207 rows × 13 columns</p>\n","</div>"],"text/plain":["              a         e          i  ...     H  albedo      moid\n","0      3.969733  0.082587   6.263280  ...  11.0   0.058  2.656530\n","1      2.262880  0.096618  22.340191  ...  17.1   0.076  1.174060\n","2      3.072270  0.103533   9.503231  ...  13.0   0.111  1.763990\n","3      2.766916  0.208954  10.208236  ...  15.0   0.044  1.182110\n","4      2.361788  0.259924   9.486384  ...  15.7   0.161  0.753967\n","...         ...       ...        ...  ...   ...     ...       ...\n","37676  3.948805  0.121336  12.100826  ...  14.5   0.044  2.510560\n","37677  2.985065  0.085091   9.437864  ...  14.4   0.111  1.737330\n","37678  2.250727  0.146572   4.952574  ...  16.1   0.242  0.917571\n","37679  2.692312  0.182102  14.004905  ...  15.9   0.088  1.240040\n","37680  2.976344  0.086984  12.570232  ...  15.9   0.025  1.752340\n","\n","[37207 rows x 13 columns]"]},"metadata":{"tags":[]},"execution_count":138}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":407},"id":"HLZ1Vl7yukZX","executionInfo":{"status":"ok","timestamp":1618282227994,"user_tz":240,"elapsed":1639,"user":{"displayName":"Alberto Bella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfYhx5QL_c7uquJXJuQgNtrIRd8B-UtT93xJ-G=s64","userId":"01742836384906309226"}},"outputId":"f9b235f8-1552-4ab5-e94a-fbf6029b0d1f"},"source":["test = pd.DataFrame(feedForward.predict(df_test[['H', 'albedo', 'i', 'w', 'om', 'a', 'q']])[:, 0])\n","test"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>25.707397</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.757519</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>15.957624</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9.553997</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4.217996</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>37202</th>\n","      <td>10.225178</td>\n","    </tr>\n","    <tr>\n","      <th>37203</th>\n","      <td>9.036356</td>\n","    </tr>\n","    <tr>\n","      <th>37204</th>\n","      <td>-0.518005</td>\n","    </tr>\n","    <tr>\n","      <th>37205</th>\n","      <td>4.011283</td>\n","    </tr>\n","    <tr>\n","      <th>37206</th>\n","      <td>5.271213</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>37207 rows × 1 columns</p>\n","</div>"],"text/plain":["               0\n","0      25.707397\n","1      -0.757519\n","2      15.957624\n","3       9.553997\n","4       4.217996\n","...          ...\n","37202  10.225178\n","37203   9.036356\n","37204  -0.518005\n","37205   4.011283\n","37206   5.271213\n","\n","[37207 rows x 1 columns]"]},"metadata":{"tags":[]},"execution_count":139}]},{"cell_type":"code","metadata":{"id":"tecJ9T0S6bD6"},"source":["test.to_csv('test.csv', index=False, header=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CpnHCRk2M-qB"},"source":["# Teoría (3 puntos)\n","Una de las ventajas al usar redes multicapas es la posiblidad de abordar problemas con múltiples clases a través de la función softmax. \n","\n","Imaginemos que tenemos una red feed forward de múltiples capas con $k$ neuronas de salidas, función de activación softmax, y función de perdida $\\displaystyle L=-\\sum_{i=1}^ky_i\\ln(o_i)$ (Note que la función de error esta definido para un punto, no un set de puntos). En este error, $o_i$ es la salida de la neurona de la clase $i$ e $y$ es un vector de $k$ valores correspondiente a la transformación one-hot-encoding de la clase (recuerde que tenemos $k$ clases).<br>\n","Por ejemplo, si el problema tiene 4 clases y el punto pertenece a la clase 3, entonces $y=[0,0,1,0]$, por lo tanto $y_1=0$, $y_2=0$, $y_3=1$ $y_4=0$.<br>\n","Note que nunca se define el número de puntos del set de datos, no importa en esta tarea.\n"," \n","Demuestre que $\\displaystyle \\frac{\\partial L}{\\partial h_i}=\\sum_{j=1}^k\\frac{\\partial L}{\\partial o_j}\\frac{\\partial o_j}{\\partial h_i}=o_i-y_i$, donde $\\displaystyle o_i=\\frac{\\exp(h_i)}{\\sum_{j=1}^k\\exp(h_j)}$ y $h_i$ es el valor continuo correspondiente a la neurona $i$ que es transformado a una probabilidad. <br><br>\n","\n","Para realizar esta demostración realize lo siguiente\n","1. Demuestre que $\\displaystyle\\frac{\\partial o_i}{\\partial h_j}=-o_io_j$ si $i\\neq j$ (1 punto)<br>\n","2. Demuestre que $\\displaystyle\\frac{\\partial o_i}{\\partial h_j}=o_i(1-o_i)$ si $i=j$ (1 punto)<br>\n","3. Utilizando las demostraciones anteriores demuestre $\\displaystyle \\frac{\\partial L}{\\partial h_i}=\\sum_{j=1}^k\\frac{\\partial L}{\\partial o_j}\\frac{\\partial o_j}{\\partial h_i}=o_i-y_i$ (1 punto)\n","\n","En caso que no pueda demostrar los puntos 1 y 2 acepte esas relaciones y demuestre directamente el punto 3 por un solo punto."]},{"cell_type":"markdown","metadata":{"id":"X3lEn_6XBoSH"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xTqJJve0vDOs"},"source":["1. Demuestre que $\\displaystyle \\frac{\\partial o_i}{\\partial h_j}=-o_io_j$ si $i\\neq j$: <br>\n","\n","Sabemos que la funcion de activiación es la función softmax\n","\n","$\\displaystyle o_i = \\frac{\\exp(h_i)}{\\sum_{j=1}^k\\exp(h_j)}$\n","\n","$\\displaystyle \\frac{\\partial o_i}{\\partial h_j} = \\frac{\\exp(h_i)\\cdot \\frac{\\partial h_i}{\\partial h_j} \\cdot \\sum_{j=1}^{k}{\\exp(h_j)} - \\exp(h_i) \\cdot \\frac{\\partial}{\\partial h_j} \\sum_{j=1}^{k}{\\exp(h_j)}}{[\\sum_{j=1}^{k}{\\exp(h_j)}]^2}$\n","\n","$\\displaystyle \\frac{\\partial o_i}{\\partial h_j} = \\frac{0 - \\exp(h_i) \\cdot \\exp(h_j)}{[\\sum_{j=1}^{k}{\\exp(h_j)}]^2} \\text{, si } i \\neq j$\n","\n","$\\displaystyle \\frac{\\partial o_i}{\\partial h_j} = \\frac{- \\exp(h_i) \\cdot \\exp(h_j)}{\\sum_{j=1}^{k}{\\exp(h_j)} \\cdot \\sum_{j=1}^{k}{\\exp(h_j)}}$\n","\n","$\\displaystyle \\frac{\\partial o_i}{\\partial h_j} = -o_io_j$\n","\n","2. Demuestre que $\\displaystyle\\frac{\\partial o_i}{\\partial h_j}=o_i(1-o_i)$ si $i=j$: <br>\n","\n","$\\displaystyle \\frac{\\partial o_i}{\\partial h_j} = \\frac{\\exp(h_i)\\cdot \\frac{\\partial h_i}{\\partial h_j} \\cdot \\sum_{j=1}^{k}{\\exp(h_j)} - \\exp(h_i) \\cdot \\frac{\\partial}{\\partial h_j} \\sum_{j=1}^{k}{\\exp(h_j)}}{[\\sum_{j=1}^{k}{\\exp(h_j)}]^2}$\n","\n","$\\displaystyle \\frac{\\partial o_i}{\\partial h_j} = \\frac{\\exp(h_i)\\cdot \\sum_{j=1}^{k}{\\exp(h_j)} - \\exp(h_i) \\cdot \\exp(h_i)}{[\\sum_{j=1}^{k}{\\exp(h_j)}]^2} \\text{, si } i = j$\n","\n","$\\displaystyle \\frac{\\partial o_i}{\\partial h_j} =\\frac{\\exp(h_i)\\cdot \\sum_{j=1}^{k}{\\exp(h_j)}}{[\\sum_{j=1}^{k}{\\exp(h_j)}]^2} - \\frac{\\exp(h_i)^2}{[\\sum_{j=1}^{k}{\\exp(h_j)}]^2}$\n","\n","$\\displaystyle \\frac{\\partial o_i}{\\partial h_j} =\\frac{\\exp(h_i)}{\\sum_{j=1}^{k}{\\exp(h_j)}} - (\\frac{\\exp(h_i)}{\\sum_{j=1}^{k}{\\exp(h_j)}})^2$\n","\n","$\\displaystyle \\frac{\\partial o_i}{\\partial h_j} = o_i - o_i^2$\n","\n","$\\displaystyle \\frac{\\partial o_i}{\\partial h_j} =o_i(1 - o_i)$\n","\n","3. Demuestre $\\displaystyle \\frac{\\partial L}{\\partial h_i}=\\sum_{j=1}^k\\frac{\\partial L}{\\partial o_j}\\frac{\\partial o_j}{\\partial h_i}=o_i-y_i$: <br>\n","\n","Sabemos que la funcion de error es la siguiente:\n","\n","$\\displaystyle L=-\\sum_{i=1}^ky_i\\ln(o_i)$\n","\n","$\\displaystyle \\frac{\\partial L}{\\partial h_i} = - \\frac{\\partial}{\\partial h_i} \\sum_{i=1}^ky_i\\ln(o_i)$\n","\n","$\\displaystyle \\frac{\\partial L}{\\partial h_i} = - \\frac{\\partial}{\\partial h_i} \\cdot [y_1 \\ln(o_1) + y_2 \\ln(o_2) + ... + y_i \\ln(o_i) + ... + y_k \\ln(o_k)] $\n","\n","$\\displaystyle \\frac{\\partial L}{\\partial h_i} = - [\\frac{\\partial}{\\partial h_i} y_1 \\ln(o_1) + \\frac{\\partial}{\\partial h_i} y_2 \\ln(o_2) + ... + \\frac{\\partial}{\\partial h_i} y_i \\ln(o_i) + ... + \\frac{\\partial}{\\partial h_i} y_k \\ln(o_k)]$\n","\n","$\\displaystyle \\frac{\\partial L}{\\partial h_i} = - [\\frac{y_1}{o_1} \\frac{\\partial o_1}{\\partial h_i} + \\frac{y_2}{o_2} \\frac{\\partial o_2}{\\partial h_i} + ... + \\frac{y_i}{o_i} \\frac{\\partial o_i}{\\partial h_i} + ... + \\frac{y_k}{o_k} \\frac{\\partial o_k}{\\partial h_i}]$\n","\n","$\\displaystyle \\frac{\\partial L}{\\partial h_i} = - [\\frac{y_1}{o_1} \\cdot (-o_i o_1) + \\frac{y_2}{o_2} \\cdot (-o_i o_2) + ... + \\frac{y_i}{o_i} \\cdot o_i (1 - o_i) + ... + \\frac{y_k}{o_k} \\cdot (-o_i o_k) ]$\n","\n","$\\displaystyle \\frac{\\partial L}{\\partial h_i} = o_i \\frac{y_1}{o_1} \\cdot o_1 + o_i \\frac{y_2}{o_2} \\cdot  o_2 + ... + o_i \\frac{y_i}{o_i} \\cdot (o_i - 1) + ... + o_i \\frac{y_k}{o_k} \\cdot  o_k$\n","\n","$\\displaystyle \\frac{\\partial L}{\\partial h_i} = o_i \\frac{y_1}{o_1} \\cdot o_1 + o_i \\frac{y_2}{o_2} \\cdot  o_2 + ... + (o_i)^2 \\frac{y_i}{o_i} - o_i \\frac{y_i}{o_i} + ... + o_i \\frac{y_k}{o_k} \\cdot  o_k$\n","\n","$\\displaystyle \\frac{\\partial L}{\\partial h_i} = o_i y_1 + o_i y_2 + ... + o_i y_i - y_i + ... + o_i y_k$\n","\n","$\\displaystyle \\frac{\\partial L}{\\partial h_i} = (o_i y_1 + o_i y_2 + ... + o_i y_i + ... + o_i y_k) - y_i$\n","\n","$\\displaystyle \\frac{\\partial L}{\\partial h_i} = o_i\\sum_{i=1}^{k}{y_i} - y_i$\n","\n","$\\displaystyle \\frac{\\partial L}{\\partial h_i} = o_i - y_i \\text{, dado que } \\sum_{i=1}^{k}{y_i} = 1$"]}]}